# Cursor Rules for eco-gotests - OCP SR-IOV Test Suite

## Project Context

This is the eco-gotests framework for testing pre-installed OCP clusters using golang and Ginkgo. The codebase follows strict conventions for test development, particularly for SR-IOV test suites.

### Project Requirements

* **golang**: v1.24.x
* **ginkgo**: v2.x
* **OCP cluster**: version >=4.13 (mandatory)

### Cluster Prerequisites

Test cases should clearly document their cluster prerequisites. Common requirements include:

* SR-IOV operator installed and healthy
* Appropriate hardware or virtualized SR-IOV interfaces available

### Supported Cluster Setups

* Regular cluster: 3 master nodes (VMs or BMs) + 2 workers (VMs or BMs)
* Single Node Cluster (VM or BM)
* Public cloud (AWS)

**WARNING!**: Some test suites of the eco-gotests framework remove existing configuration such as PtpConfig, SR-IOV, SriovFecClusterConfig configs. If tests delete or modify existing Custom Resources (CRs), they must capture them at `BeforeAll`/`BeforeSuite` level and restore them at `AfterAll`/`AfterSuite` level to maintain cluster state.

## Directory Structure

### Test Suite Organization

For OCP SR-IOV tests, follow this structure:

```
tests/ocp/sriov/
├── internal/                    # Internal packages used within test suite
│   ├── tsparams/               # Test suite constants and parameters
│   │   ├── consts.go           # Constants (labels, timeouts, names)
│   │   └── sriovvars.go        # Variables and configuration
│   └── sriovenv/               # Environment validation and helpers
│       └── sriovenv.go
├── tests/                      # Test case implementations
│   ├── testcase1.go
│   └── testcase2.go
└── sriov_suite_test.go         # Ginkgo test suite entry point
```

### Code Organization Rules

**CRITICAL**: Reusable functions that can be used across multiple test suites should be placed in the upper-level `internal/` folder (e.g., `tests/internal/`), NOT in the test suite-specific `internal/` folder.

1. **Suite-specific helpers**: Place in `tests/ocp/sriov/internal/`
   - Functions specific to SR-IOV test suite only
   - Test parameters and constants specific to this suite

2. **Reusable/common helpers**: Place in `tests/internal/`
   - Functions that can be used by multiple test suites
   - Common utilities and helpers
   - Shared validation logic

## Naming Conventions

1. **Package Names**: Use lowercase, descriptive names (e.g., `tsparams`, `sriovenv`)
2. **File Names**: Use lowercase with underscores or camelCase (e.g., `metricsExporter.go`, `webhook-matchConditions.go`)
3. **Test Files**: Place in `tests/` subdirectory, one file per test scenario or feature group
4. **Suite File**: Named as `{suite}_suite_test.go` (e.g., `sriov_suite_test.go`)

## Import Restrictions - CRITICAL

### Helper Functions in `internal/` Folders

**MANDATORY RULES**:

1. **NO Gomega/Ginkgo imports in helpers**: Gomega and Ginkgo should ONLY be imported in:
   - Test suite files (e.g., `*_suite_test.go`)
   - Test files in `tests/` directory
   
   Helper functions in `internal/` folders MUST NOT import:
   - `github.com/onsi/gomega`
   - `github.com/onsi/ginkgo/v2`

2. **NO Eventually in internal folders**: The `Eventually` function from Gomega must NOT be used in any `internal/` folder. It is acceptable to use `Eventually` in test suite files where Gomega is properly imported.

3. **Helpers return errors**: Helper functions should always return errors instead of calling `Fail()` or using Gomega matchers. Let the test code handle failures using Gomega assertions.

### Correct Helper Function Pattern

```go
// ✅ CORRECT: Helper in internal/ folder
package sriovenv

func ValidateSriovInterfaces(nodeList []*nodes.Builder, minCount int) error {
    if len(nodeList) < minCount {
        return fmt.Errorf("insufficient nodes: got %d, need %d", len(nodeList), minCount)
    }
    return nil
}
```

### Incorrect Helper Function Pattern

```go
// ❌ INCORRECT: Using Gomega in helper
package sriovenv

import . "github.com/onsi/gomega"  // ❌ Don't import Gomega in helpers

func ValidateSriovInterfaces(nodeList []*nodes.Builder, minCount int) {
    Expect(len(nodeList)).To(BeNumerically(">=", minCount))  // ❌ Don't use Gomega matchers
}
```

### Polling in Helper Functions

In helper functions (in `internal/` folders), use either:
- **eco-goinfra WaitFor methods**: Use built-in `WaitForX` methods from eco-goinfra builders (e.g., `pod.WaitForReady()`, `deployment.WaitForReady()`, `builder.WaitForCondition()`)
- **wait.PollUntilContextTimeout**: Use `k8s.io/apimachinery/pkg/util/wait.PollUntilContextTimeout` for custom polling logic

**DO NOT** use `Eventually` in helper functions.

## Test Case Structure

### Basic Ginkgo Test Pattern

```go
var _ = Describe(
    "TestFeatureName", 
    Ordered, 
    Label(tsparams.LabelFeatureName), 
    ContinueOnFailure, 
    func() {
        var (
            // Shared test variables
        )

        BeforeAll(func() {
            // Setup required for all tests in this Describe block
            By("Setting up test environment")
            // ... setup code ...
        })

        AfterAll(func() {
            // Cleanup after all tests
            By("Cleaning up test resources")
            // ... cleanup code ...
        })

        BeforeEach(func() {
            // Setup for each test
        })

        AfterEach(func() {
            // Cleanup after each test
        })

        It("should perform specific test action", reportxml.ID("12345"), func() {
            By("Step description")
            // Test implementation
        })
    })
```

### Test Organization Principles

1. **Ordered Tests**: Use `Ordered` when tests must run in sequence
2. **Labels**: Always use labels for test filtering (`Label(tsparams.LabelFeatureName)`)
3. **ContinueOnFailure**: 
   - Typically used in conjunction with `Ordered` containers
   - In an `Ordered` container, if a test fails, remaining tests won't execute by default. Use `ContinueOnFailure` to allow remaining tests to run even after a failure
   - If `Ordered` is not used, continuing on failure is the default behavior
4. **Test IDs**: Use `reportxml.ID("12345")` for each test case
5. **Descriptive Names**: Test descriptions should clearly state what is being tested

### Test Labels

- Use lowercase with hyphens or underscores
- Be specific and descriptive
- Group related tests under the same label
- Define labels in `internal/tsparams/consts.go`

Example:
```go
const (
    LabelSuite = "sriov"
    LabelFeatureName = "feature-name"
    LabelHWEnabled = "sriov-hw-enabled"
)
```

## Error Handling

1. **Always check errors**: Don't ignore errors; handle them appropriately
2. **Use Gomega matchers**: Prefer `Expect(err).ToNot(HaveOccurred())` for assertions
3. **Descriptive error messages**: Include context in error messages
4. **Matcher arguments support formatting**: Gomega matcher error messages support formatting (similar to `fmt.Printf`). Use `%q`, `%s`, `%d`, etc. to format values in error messages
5. **Add diagnostic callbacks**: When assertions fail, provide additional context using diagnostic callbacks. Pass a function that returns a string as the optional description parameter.

Example with diagnostic callback:
```go
// Simple error message with formatting
Expect(err).ToNot(HaveOccurred(), "Failed to create test namespace %q", testNS.Definition.Name)

// Error message with diagnostic callback for additional context
Expect(pod.IsReady()).To(BeTrue(), func() string {
    // This callback is only executed when the assertion fails
    podLogs, _ := pod.GetLogs()
    podStatus, _ := pod.GetStatus()
    return fmt.Sprintf("Pod %q is not ready. Status: %s\nPod logs:\n%s", 
        pod.Definition.Name, podStatus, podLogs)
})
```

## Resource Management

1. **Create resources in BeforeAll/BeforeEach**: Set up test prerequisites
2. **Cleanup in AfterAll/AfterEach**: Always clean up created resources
3. **Use DeferCleanup**: For guaranteed cleanup even on test failure
4. **Unique names**: Use unique namespaces or resource names to avoid conflicts
5. **Recover existing CRs**: If tests delete or modify existing Custom Resources (CRs), capture them at `BeforeAll`/`BeforeSuite` level and restore them at `AfterAll`/`AfterSuite` level to maintain cluster state

Example:
```go
var existingCRs []*sriov.PolicyBuilder

BeforeAll(func() {
    // Capture existing CRs before test modifications
    existingCRs = captureExistingPolicies(APIClient)
    
    testNS := namespace.NewBuilder(APIClient, tsparams.TestNamespaceName)
    _, err := testNS.Create()
    Expect(err).ToNot(HaveOccurred(), "Failed to create test namespace %q", testNS.Definition.Name)
})

AfterAll(func() {
    // Restore captured CRs
    restoreExistingPolicies(APIClient, existingCRs)
    
    err := testNS.DeleteAndWait(tsparams.DefaultTimeout)
    Expect(err).ToNot(HaveOccurred(), "Failed to delete test namespace")
})
```

## Timeouts and Polling

1. **Use appropriate timeouts**: Don't use hardcoded timeouts; use constants from `tsparams`
2. **Consistent polling intervals**: Use `tsparams.RetryInterval` for consistency
3. **Eventually vs Consistently**: 
   - Use `Eventually` for waiting for a condition to become true (in test files only)
   - Use `Consistently` for verifying a condition remains true
4. **Stable duration**: Use `StableFor` or similar when verifying stability
5. **In test files**: Use `Eventually` from Gomega for polling and waiting
6. **In helper functions**: Use eco-goinfra `WaitForX` methods or `wait.PollUntilContextTimeout`

Example in test file:
```go
Eventually(func() bool {
    // Check condition
    return condition
}, tsparams.WaitTimeout, tsparams.RetryInterval).Should(BeTrue(), "Condition description")
```

## Logging and Debugging

1. **Use By() statements**: Document test steps with `By("Description")`
2. **Glog for verbose logging**: Use `glog.V(level).Infof()` for detailed logging
3. **Environment variable control**: Respect `ECO_VERBOSE_LEVEL` for logging verbosity
4. **Meaningful messages**: Include context in log messages

Example:
```go
By("Creating SR-IOV network policy")
glog.V(90).Infof("Creating policy with name: %s", policyName)
```

## Test Isolation

1. **Independent tests**: Tests should be able to run independently
2. **Isolated namespaces**: Use separate namespaces per test suite
3. **No shared state**: Avoid shared state between tests unless using `Ordered`
4. **Cleanup verification**: Verify cleanup completed successfully

## Reporter Integration

1. **Report on failure**: Use `JustAfterEach` with `reporter.ReportIfFailed`
2. **Configure CRDs to dump**: Define in `tsparams.ReporterCRDsToDump`
3. **Configure namespaces**: Define in `tsparams.ReporterNamespacesToDump`
4. **XML reports**: Ensure suite file includes `ReportAfterSuite` for XML generation

Example:
```go
var _ = JustAfterEach(func() {
    reporter.ReportIfFailed(
        CurrentSpecReport(), 
        currentFile, 
        tsparams.ReporterNamespacesToDump, 
        tsparams.ReporterCRDsToDump)
})

var _ = ReportAfterSuite("", func(report Report) {
    reportxml.Create(report, NetConfig.GetReportPath(), NetConfig.TCPrefix)
})
```

## Environment Variables

### Mandatory Environment Variables

* `KUBECONFIG` - Path to kubeconfig file (required for all tests)

### General Framework Environment Variables

#### Logging with glog

To enable verbose logging:

1. Import inittools in your go script:
```go
import (
    . "github.com/rh-ecosystem-edge/eco-gotests/tests/internal/inittools"
)
```

**Note**: The go file must be in a directory under `github.com/rh-ecosystem-edge/eco-gotests/tests/` to import inittools.

2. Export the following environment variable:
```bash
export ECO_VERBOSE_LEVEL=100  # Value must be >= 100
```

**Important Notes**:
- The value for `ECO_VERBOSE_LEVEL` must be >= 100
- The variable can be exported in the shell where you run your automation
- Importing inittools also initializes the apiclient, available via `APIClient` variable

#### Collect logs from cluster with reporter

To enable k8reporter for collecting resources on test failure:

```bash
export ECO_DUMP_FAILED_TESTS=true
export ECO_REPORTS_DUMP_DIR=/tmp/logs_directory  # Default: /tmp/reports
```

#### XML Report Generation

XML reports are enabled by default. To disable:

```bash
export ECO_ENABLE_REPORT=false
```

#### Test Execution Environment Variables

For running tests via test-runner script:

- `ECO_TEST_FEATURES`: List of features to test ("all" includes all tests) - **required**
- `ECO_TEST_LABELS`: Ginkgo query for label filtering - _optional_
- `ECO_VERBOSE_SCRIPT`: Print verbose script information - _optional_
- `ECO_TEST_VERBOSE`: Execute ginkgo with verbose output - _optional_
- `ECO_TEST_TRACE`: Include full stack trace on failure - _optional_

Example:
```bash
export KUBECONFIG=/path/to/kubeconfig
export ECO_TEST_FEATURES="sriov"
export ECO_TEST_LABELS="sriov && feature-name"
make run-tests
```

### Suite-Specific Environment Variables

#### Naming Convention

Follow the pattern: `ECO_{SUITE}_{FEATURE}_{PARAMETER}`

Examples:
- `ECO_OCP_SRIOV_INTERFACE_LIST`
- `ECO_OCP_SRIOV_TEST_IMAGE`
- `ECO_OCP_SRIOV_WORKER_LABEL`

### Configuration Management

1. **Centralized config**: Use configuration structs from `internal/netconfig` or similar
2. **Environment variable mapping**: Map environment variables to config structs
3. **Default values**: Provide sensible defaults
4. **Validation**: Validate required configuration before tests run

## Code Quality and Best Practices

### Linting

- **golangci-lint**: All PRs are tested with golangci-lint in the pipeline
- **Pre-PR check**: Always run `make lint` before uploading a PR
- **Editor integration**: It's advised to add [Golangci-lint integration](https://golangci-lint.run/usage/integrations/) to your development editor
- **Common issue**: If automated commit check fails, pull/rebase latest changes and ensure `make lint` passes locally first

### Function Formatting

Follow the project's function formatting conventions:

```go
// Single line if arguments fit
func Function(arg1, arg2 int, arg3 string) error {
    // ...
}

// Multi-line if arguments don't fit
func Function(
    arg1 int,
    arg2 int,
    arg3 string,
    arg4 []string) error {
    // ...
}
```

Additional acceptable format (grouping parameters of same type):
```go
func Function(
    argInt1, argInt2 int, argString1, argString2 string, argSlice1, argSlice2 []string) error {
    // ...
}
```

### Use of eco-goinfra Packages - MANDATORY

**CRITICAL RULE**: All Kubernetes API interactions MUST go through eco-goinfra packages. Do NOT use raw Kubernetes client calls directly.

1. **All API calls must use eco-goinfra**: All Kubernetes API interactions must go through eco-goinfra packages
2. **Prefer eco-goinfra**: Use eco-goinfra packages for Kubernetes resource management
3. **Avoid raw client calls**: Use builder patterns when available. Direct API client usage is NOT allowed
4. **If eco-goinfra lacks functionality**: If a required feature is missing in eco-goinfra, contribute it to the eco-goinfra project rather than implementing raw client calls in test code

Common packages:
- `github.com/rh-ecosystem-edge/eco-goinfra/pkg/sriov`
- `github.com/rh-ecosystem-edge/eco-goinfra/pkg/pod`
- `github.com/rh-ecosystem-edge/eco-goinfra/pkg/namespace`
- `github.com/rh-ecosystem-edge/eco-goinfra/pkg/nodes`

## Commit Message Guidelines - MANDATORY

**CRITICAL**: All commit messages must identify the team in the commit title.

### Commit Message Format

There are two main components of a Git commit message: the title (or summary) and the description. The commit message title is limited to 72 characters, and the description has no character limit.

Commit title format has two parts:
1. **Team name prefix**: Must start with the team identifier (e.g., `ocp-sriov:`, `cnf network:`, `hw-accel:`)
2. **Short summary**: Brief description of the code changes

### Commit Message Examples

```
ocp-sriov: added metrics exporter test case
ocp-sriov: fixed timeout handling in network policy test
ocp-sriov: updated environment variable documentation
infra: func defineNetwork moved to global net package
readme: added commit message convention
ci: added new deployment job
cnf network: added set func to cluster pkg
```

### Rules for Commit Messages

- **Team prefix is mandatory**: Always prefix with team name (e.g., `ocp-sriov:`, `cnf network:`)
- **Special prefixes**: 
  - Use `infra:` for changes to multiple team's directories or common infrastructure code
  - Use `readme:` for README file changes
  - Use `ci:` for GitHub CI file changes
- **Use lowercase**: Team prefix should be lowercase with hyphens or spaces (as per team convention)
- **No test IDs**: Don't include internal test IDs in commit messages
- **No capital letters**: Avoid capital letters in commit message titles
- **72 character limit**: Commit title should be limited to 72 characters
- **Description optional**: Detailed explanation can be added in commit description if needed

## Common Patterns

### Resource Creation Pattern

```go
resource := builder.NewBuilder(APIClient, name, namespace)
resource.WithLabel("key", "value")
resourceObject, err := resource.Create()
Expect(err).ToNot(HaveOccurred(), "Failed to create resource")
```

### Resource Cleanup Pattern

```go
DeferCleanup(func() {
    err := resource.Delete()
    Expect(err).ToNot(HaveOccurred(), "Failed to delete resource")
})
```

### Validation Pattern (in test files)

```go
Eventually(func() bool {
    obj, err := builder.Pull(APIClient, name, namespace)
    if err != nil {
        return false
    }
    return obj.IsReady()
}, timeout, interval).Should(BeTrue(), "Resource should be ready")
```

### Test Data Pattern

```go
type testData struct {
    policy  *sriov.PolicyBuilder
    network *sriov.NetworkBuilder
    pod     *pod.Builder
}

var testResources []testData

BeforeEach(func() {
    testResources = []testData{}
})
```

## Pre-Submit Checklist

Before submitting code, ensure:

- [ ] Test follows directory structure conventions
- [ ] All required labels are defined in `tsparams/consts.go`
- [ ] Test IDs are included using `reportxml.ID()`
- [ ] Resources are properly cleaned up in `AfterEach` or `AfterAll`
- [ ] Error handling is comprehensive
- [ ] Timeouts use constants from `tsparams`
- [ ] `By()` statements document test steps
- [ ] Reporter is configured for failure reporting
- [ ] Environment variables are documented in README
- [ ] Test can run independently (unless using `Ordered`)
- [ ] Code passes linting (`make lint`) - **run before PR**
- [ ] Test descriptions are clear and descriptive
- [ ] README is updated with new features or environment variables
- [ ] **All API calls use eco-goinfra packages** (no raw Kubernetes client calls)
- [ ] **Reusable functions are placed in upper-level `tests/internal/` folder**
- [ ] **Helper functions in `internal/` folders do NOT import Gomega/Ginkgo**
- [ ] **Helper functions in `internal/` folders do NOT use `Eventually`**
- [ ] **Commit message includes team prefix** (e.g., `ocp-sriov: description`)

## Key Reminders

1. **NO Gomega/Ginkgo in `internal/` folders**: Helper functions must return errors, not use Gomega matchers
2. **NO `Eventually` in `internal/` folders**: Use eco-goinfra `WaitForX` methods or `wait.PollUntilContextTimeout`
3. **ALL API calls through eco-goinfra**: Never use raw Kubernetes client calls
4. **Team prefix in commits**: Always prefix commit messages with team name (e.g., `ocp-sriov:`, `cnf network:`) or special prefixes (`infra:`, `readme:`, `ci:`)
5. **Reusable helpers go to `tests/internal/`**: Not in suite-specific `internal/` folders
6. **Run `make lint` before PR**: Always ensure linting passes locally before submitting PR
7. **Import inittools for logging**: Import inittools to enable glog verbose logging and initialize APIClient

## Test Execution

### Running Tests

The test-runner script is the recommended way for executing tests. Use `make run-tests` to execute the runner script.

**Note**: The test-runner script automatically includes all subdirectories under `tests/` that match the feature name (internal directories are excluded).

Example:
```bash
export KUBECONFIG=/path/to/kubeconfig
export ECO_TEST_FEATURES="sriov"
export ECO_TEST_LABELS="sriov && feature-name"
make run-tests
```

### Test Filtering

- **By feature**: Use `ECO_TEST_FEATURES` to select test suites (use "all" to include all tests)
- **By label**: Use `ECO_TEST_LABELS` with ginkgo label filtering syntax
- **By test ID**: Test IDs can be used as labels in `ECO_TEST_LABELS`

Examples:
```bash
# Run only specific label
export ECO_TEST_LABELS="sriov && feature-name"

# Exclude specific label
export ECO_TEST_LABELS="sriov && !skip-in-ci"

# Run specific test ID (test IDs can be used as labels)
export ECO_TEST_LABELS="12345"

# Run multiple test IDs
export ECO_TEST_LABELS="12345 || 12346"
```

